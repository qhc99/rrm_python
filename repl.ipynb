{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRMConvNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(0, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Conv2d(256, 256, kernel_size=(1, 31), stride=(1, 1), padding=(0, 15))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Conv2d(256, 256, kernel_size=(1, 31), stride=(1, 1), padding=(0, 15))\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Flatten(start_dim=1, end_dim=-1)\n",
      "    (11): Linear(in_features=3840, out_features=15, bias=True)\n",
      "    (12): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "import torch.nn as TorchNN\n",
    "from config import TRAIN_BATCH_SIZE, TEST_BATCH_SIZE, LR, EPOCH, \\\n",
    "    RUNNING_LOSS_PERIOD, DATASET_TYPE, MODEL_TYPE, TRAINING\n",
    "from torch.utils.data import DataLoader\n",
    "from tkinter import filedialog, Tk\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "import torch.nn as TorchNN\n",
    "from config import TRAIN_BATCH_SIZE, TEST_BATCH_SIZE, LR, EPOCH, \\\n",
    "    RUNNING_LOSS_PERIOD, DATASET_TYPE, MODEL_TYPE, TRAINING\n",
    "from torch.utils.data import DataLoader\n",
    "from tkinter import filedialog, Tk\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "print(torch.__version__)\n",
    "\n",
    "# load and transform\n",
    "data = loadmat(\"dataset.mat\")\n",
    "XTrain = data[\"XTrain\"]\n",
    "XValidation = data[\"XValidation\"]\n",
    "\n",
    "YTrain = data[\"YTrain\"]\n",
    "YValidation = data[\"YValidation\"]\n",
    "\n",
    "XTrain = XTrain.transpose([3, 2, 0, 1])\n",
    "XValidation = XValidation.transpose([3, 2, 0, 1])\n",
    "\n",
    "# train\n",
    "root = Tk()\n",
    "model_name = filedialog.askopenfile(filetypes=[(\"model file\", \"*.pt\")], initialdir=\"./checkpoints\")\n",
    "root.destroy()\n",
    "\n",
    "criterion = TorchNN.MSELoss()\n",
    "model = MODEL_TYPE(5, 15) if model_name is None else torch.load(model_name.name)\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train_set = DATASET_TYPE(XTrain, YTrain)\n",
    "train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "test_set = DATASET_TYPE(XValidation, YValidation)\n",
    "test_loader = DataLoader(test_set, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "def avg_loss(LOADER):\n",
    "    _running_loss = 0.0\n",
    "    for i, _data in enumerate(LOADER, 0):\n",
    "        _inputs, _labels = _data\n",
    "        _inputs = _inputs.to(device)\n",
    "        _labels = _labels.to(device)\n",
    "        _outputs = model(_inputs)\n",
    "        _loss = criterion(_outputs, _labels)\n",
    "        _running_loss += _loss.item()\n",
    "    return _running_loss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "print(torch.__version__)\n",
    "\n",
    "# load and transform\n",
    "data = loadmat(\"dataset.mat\")\n",
    "XTrain = data[\"XTrain\"]\n",
    "XValidation = data[\"XValidation\"]\n",
    "\n",
    "YTrain = data[\"YTrain\"]\n",
    "YValidation = data[\"YValidation\"]\n",
    "\n",
    "XTrain = XTrain.transpose([3, 2, 0, 1])\n",
    "XValidation = XValidation.transpose([3, 2, 0, 1])\n",
    "\n",
    "# train\n",
    "root = Tk()\n",
    "model_name = filedialog.askopenfile(filetypes=[(\"model file\", \"*.pt\")], initialdir=\"./checkpoints\")\n",
    "root.destroy()\n",
    "\n",
    "criterion = TorchNN.MSELoss()\n",
    "model = MODEL_TYPE(5, 15) if model_name is None else torch.load(model_name.name)\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train_set = DATASET_TYPE(XTrain, YTrain)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False)\n",
    "test_set = DATASET_TYPE(XValidation, YValidation)\n",
    "test_loader = DataLoader(test_set, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_time = datetime.datetime.now().strftime('%Y_%m_%d,%H.%M.%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}